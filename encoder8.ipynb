{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a0064a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdteakhperky\u001b[0m (\u001b[33mdteakhperky-higher-school-of-economics\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "from torch import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from utils import DataPathWrapper\n",
    "\n",
    "import time\n",
    "import utils\n",
    "\n",
    "import monai\n",
    "import monai.transforms as mt\n",
    "\n",
    "import pypickle\n",
    "\n",
    "import medim\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import get_dataset\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d882b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD_PATH = Path(os.getcwd())\n",
    "BMMAE_PATH = CWD_PATH / \"BM-MAE\"\n",
    "\n",
    "sys.path.append(str(BMMAE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5768c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmmae.model import ViTEncoder\n",
    "from bmmae.tokenizers import MRITokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0944a35",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7913ddab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69372fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0xBAD5EED):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bb56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964726aa",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303031cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD_PATH = Path(os.getcwd())\n",
    "DATA_PATH = CWD_PATH / \"data\"\n",
    "\n",
    "ATLAS_DATA_PATH = DATA_PATH / \"Lumiere\" / \"atlas_mapping\"\n",
    "SPLIT_PATH = CWD_PATH / \"splits\" / \"split.pkl\"\n",
    "\n",
    "split = pypickle.load(SPLIT_PATH, verbose=\"silent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e92b44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai.transforms as mt\n",
    "import numpy as np\n",
    "\n",
    "class CropAroundMaskd(mt.MapTransform):\n",
    "    \"\"\"\n",
    "    Crop a region around the non-zero area of a mask with a specified margin.\n",
    "    If the mask is empty (no foreground), returns the original images without cropping.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keys, mask_key, margin=10):\n",
    "        super().__init__(keys)\n",
    "        self.mask_key = mask_key\n",
    "        self.margin = margin\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        mask = d[self.mask_key][0]  # assuming mask shape (C=1, H, W, D)\n",
    "\n",
    "        nonzero = np.nonzero(mask)\n",
    "        if len(nonzero[0]) == 0:\n",
    "            # Mask is empty: skip cropping and return original images\n",
    "            return d\n",
    "\n",
    "        minz, maxz = nonzero[0].min(), nonzero[0].max()\n",
    "        miny, maxy = nonzero[1].min(), nonzero[1].max()\n",
    "        minx, maxx = nonzero[2].min(), nonzero[2].max()\n",
    "\n",
    "        shape = mask.shape\n",
    "        minz = max(minz - self.margin, 0)\n",
    "        maxz = min(maxz + self.margin + 1, shape[0])\n",
    "        miny = max(miny - self.margin, 0)\n",
    "        maxy = min(maxy + self.margin + 1, shape[1])\n",
    "        minx = max(minx - self.margin, 0)\n",
    "        maxx = min(maxx + self.margin + 1, shape[2])\n",
    "\n",
    "        for key in self.keys:\n",
    "            img = d[key]\n",
    "            # img shape assumed (C, H, W, D)\n",
    "            d[key] = img[:, minz:maxz, miny:maxy, minx:maxx]\n",
    "\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9525f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_image_keys = ['baseline_FLAIR', 'baseline_T1', 'baseline_T1CE', 'baseline_T2', 'baseline_seg']\n",
    "followup_image_keys = ['followup_FLAIR', 'followup_T1', 'followup_T1CE', 'followup_T2', 'followup_seg']\n",
    "keys = baseline_image_keys + followup_image_keys\n",
    "\n",
    "train_transform = mt.Compose([\n",
    "    mt.LoadImaged(keys=keys),\n",
    "    mt.EnsureChannelFirstd(keys=keys),\n",
    "    mt.EnsureTyped(keys=keys),\n",
    "    mt.Spacingd(keys=keys, pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\")),\n",
    "    # Crop around tumor mask with margin 10 voxels\n",
    "    CropAroundMaskd(keys=[key for key in baseline_image_keys if \"seg\" not in key], mask_key=\"baseline_seg\", margin=10),\n",
    "    CropAroundMaskd(keys=[key for key in followup_image_keys if \"seg\" not in key], mask_key=\"followup_seg\", margin=10),\n",
    "    # Now you can apply random crops or other augmentations on the cropped ROI\n",
    "    # mt.RandCropByPosNegLabeld(\n",
    "    #     keys=keys,\n",
    "    #     label_key=\"baseline_seg\",\n",
    "    #     spatial_size=(128, 128, 128),\n",
    "    #     pos=1,\n",
    "    #     num_samples=1,\n",
    "    #     image_key=baseline_image_keys[0]\n",
    "    # ),\n",
    "    mt.RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "    mt.RandFlipd(keys=keys, prob=0.5, spatial_axis=1),\n",
    "    mt.RandFlipd(keys=keys, prob=0.5, spatial_axis=2),\n",
    "    mt.NormalizeIntensityd(keys=keys, nonzero=True, channel_wise=True),\n",
    "    mt.RandScaleIntensityd(keys=keys, factors=0.1, prob=1.0),\n",
    "    mt.RandShiftIntensityd(keys=keys, offsets=0.1, prob=1.0),\n",
    "    mt.DeleteItemsd(keys=[\"baseline_seg\", \"followup_seg\"]),\n",
    "    mt.ResizeD(keys=[img for img in keys if \"seg\" not in img], spatial_size=(128, 128, 128)),\n",
    "]).set_random_state(seed=0xBAD5EED)\n",
    "\n",
    "# train_transform = mt.Compose([\n",
    "#     mt.LoadImaged(keys=keys),\n",
    "#     mt.EnsureChannelFirstd(keys=keys),\n",
    "#     mt.EnsureTyped(keys=keys),\n",
    "#     # mt.Orientationd(keys=keys, axcodes=\"RAS\"),\n",
    "#     # Spatial augmentations\n",
    "#     # mt.RandRotated(keys=keys, range_x=0.3, prob=0.5),\n",
    "#     # mt.RandZoomd(keys=keys, min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "#     # Intensity augmentations\n",
    "#     # mt.RandGaussianNoised(keys=keys, std=0.01, prob=0.2),\n",
    "#     # mt.RandAdjustContrastd(keys=keys, gamma=(0.7, 1.3), prob=0.3),\n",
    "#     # Normalization\n",
    "#     # mt.ScaleIntensityd(keys=keys),\n",
    "#     # mt.ScaleIntensityRangePercentilesd(keys=keys, lower=5, upper=95, b_min=0, b_max=1),\n",
    "#     mt.Spacingd(keys=keys, pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\")),\n",
    "#     # mt.CenterSpatialCropd(keys=keys, roi_size=[128, 128, 128]),\n",
    "#     mt.RandCropByPosNegLabeld(\n",
    "#         keys=keys,\n",
    "#         label_key=\"baseline_seg\",  # Use your segmentation mask\n",
    "#         spatial_size=(128,128,128),\n",
    "#         pos=1,  # Force tumor presence\n",
    "#         num_samples=1,\n",
    "#         image_key=baseline_image_keys[0]\n",
    "#     ),\n",
    "#     mt.RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "#     mt.RandFlipd(keys=keys, prob=0.5, spatial_axis=1),\n",
    "#     mt.RandFlipd(keys=keys, prob=0.5, spatial_axis=2),\n",
    "#     mt.NormalizeIntensityd(keys=keys, nonzero=True, channel_wise=True),\n",
    "#     mt.RandScaleIntensityd(keys=keys, factors=0.1, prob=1.0),\n",
    "#     mt.RandShiftIntensityd(keys=keys, offsets=0.1, prob=1.0),\n",
    "#     # mt.RandGaussianNoised(keys=[key for key in keys if key not in [\"baseline_seg\", \"followup_seg\"]], std=0.01, prob=0.3),  # Exclude segs\n",
    "#     # mt.ConcatItemsd(keys=keys, name=\"images\"),\n",
    "#     # mt.DeleteItemsd(keys=keys),\n",
    "#     # mt.RandFlipd(keys=[\"images\"]),\n",
    "#     # mt.RandBiasFieldd(keys=[\"images\"], prob=0.5),\n",
    "#     mt.DeleteItemsd(keys=[\"baseline_seg\", \"followup_seg\"]),\n",
    "#     mt.ResizeD(keys=[img for img in keys if \"seg\" not in img], spatial_size=(128, 128, 128)),\n",
    "#     # mt.RandCropByPosNegLabeld(\n",
    "#     #     keys=[\"images\"],\n",
    "#     #     label_key=\"baseline_seg\",\n",
    "#     #     spatial_size=(128, 128, 64),\n",
    "#     #     pos=1, neg=1, num_samples=4,\n",
    "#     #     image_key=\"images\", prob=0.5\n",
    "#     # ),\n",
    "#     # mt.ConcatItemsd(keys=followup_image_keys, name=\"followup\"),\n",
    "#     # mt.ToTensord(keys=keys)\n",
    "# ]).set_random_state(seed=0xBAD5EED)\n",
    "\n",
    "valid_transform = mt.Compose([\n",
    "    mt.LoadImaged(keys=keys),\n",
    "    mt.EnsureChannelFirstd(keys=keys),\n",
    "    mt.EnsureTyped(keys=keys),\n",
    "    # mt.Orientationd(keys=keys, axcodes=\"RAS\"),\n",
    "    # mt.ConcatItemsd(keys=baseline_image_keys, name=\"baseline\", dim=0),\n",
    "    # mt.ConcatItemsd(keys=followup_image_keys, name=\"followup\", dim=0),\n",
    "    # mt.ScaleIntensityd(keys=keys),\n",
    "    mt.Spacingd(keys=keys, pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\")),\n",
    "    # mt.CenterSpatialCropd(keys=keys, roi_size=[128, 128, 128]),\n",
    "    CropAroundMaskd(keys=[key for key in baseline_image_keys if \"seg\" not in key], mask_key=\"baseline_seg\", margin=10),\n",
    "    CropAroundMaskd(keys=[key for key in followup_image_keys if \"seg\" not in key], mask_key=\"followup_seg\", margin=10),\n",
    "    # mt.RandCropByPosNegLabeld(\n",
    "    #     keys=keys,\n",
    "    #     label_key=\"baseline_seg\",  # Use your segmentation mask\n",
    "    #     spatial_size=(128,128,128),\n",
    "    #     pos=1,  # Force tumor presence\n",
    "    #     num_samples=1,\n",
    "    #     image_key=baseline_image_keys[0]\n",
    "    # ),\n",
    "    mt.NormalizeIntensityd(keys=keys, nonzero=True, channel_wise=True),\n",
    "    # mt.ConcatItemsD(keys=keys, name=\"images\", dim=0),\n",
    "    mt.DeleteItemsd(keys=[\"baseline_seg\", \"followup_seg\"]),\n",
    "    mt.ResizeD(keys=[img for img in keys if \"seg\" not in img], spatial_size=(128, 128, 128)),\n",
    "    # mt.ToTensord(keys=[\"baseline\", \"followup\"]),\n",
    "    # mt.ToTensord(keys=keys)\n",
    "]).set_random_state(seed=0xBAD5EED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922400d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 84)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = get_dataset(\n",
    "    data_path=ATLAS_DATA_PATH,\n",
    "    indices=split[\"train_patient_ids\"],\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "valid_dataset = get_dataset(\n",
    "    data_path=ATLAS_DATA_PATH,\n",
    "    indices=split[\"valid_patient_ids\"],\n",
    "    transform=valid_transform\n",
    ")\n",
    "\n",
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c668918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14-07-2025 19:01:20] [pypickle.pypickle] [WARNING] [FAILED]: File not saved. File already exists: [./labels.pkl]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(\"./labels.pkl\"):\n",
    "    labels = pypickle.load(\"./labels.pkl\", verbose=\"silent\")\n",
    "else:\n",
    "    labels = [sample[\"label\"] for sample in train_dataset]\n",
    "pypickle.save(\"./labels.pkl\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa4c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "class_counts = torch.bincount(torch.tensor(labels))\n",
    "temperature = 1.0\n",
    "weights = (1 / class_counts.float()) ** temperature\n",
    "weights /= weights.sum()\n",
    "samples_weights = weights[labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=samples_weights,\n",
    "    num_samples=len(samples_weights),\n",
    "    replacement=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afcf612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # shuffle=True,\n",
    "    sampler=sampler,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae7dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))[\"images\"].shape, next(iter(valid_loader))[\"images\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35cc21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f9f6a",
   "metadata": {},
   "source": [
    "# Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "741299f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def test_model_correctness(model, loader):\n",
    "    images = next(iter(loader))\n",
    "    baseline_images = {\n",
    "        key.split(\"_\")[-1]: images[key].to(device) for key in baseline_image_keys if \"seg\" not in key\n",
    "    }\n",
    "    followup_images = {\n",
    "        key.split(\"_\")[-1]: images[key].to(device) for key in followup_image_keys if \"seg\" not in key\n",
    "    }\n",
    "    model = model.to(device)\n",
    "    outputs = model(baseline_images, followup_images).cpu().numpy()\n",
    "    assert outputs.shape[-1] == 4, f'Wrong last output dimension. Expected {4}; Got {outputs.shape[-1]}'\n",
    "    print('All gucci')\n",
    "\n",
    "def calculate_receptive_field(params: list[tuple[int, int]]) -> int:\n",
    "    r, s = 1, 1\n",
    "    for kernel_size, stride in params:\n",
    "        r += (kernel_size - 1) * stride\n",
    "        s *= stride\n",
    "    \n",
    "    return r\n",
    "\n",
    "def calculate_params(model: torch.nn.Module) -> int:\n",
    "    return f'{sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.2f} M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321d5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, \n",
    "    loader, \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler=None, \n",
    "    wandb_logging=False,\n",
    "    accumulation_steps=4\n",
    "):\n",
    "    model.train()\n",
    "    scaler = GradScaler()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    step_count = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    for i, batch in enumerate(tqdm(loader, leave=False)):\n",
    "        # batch = batch[0]\n",
    "        batch[\"label\"] = batch[\"label\"].to(device)\n",
    "        baseline_images = {\n",
    "            key.split(\"_\")[-1]: batch[key].to(device) for key in baseline_image_keys if \"seg\" not in key\n",
    "        }\n",
    "        followup_images = {\n",
    "            key.split(\"_\")[-1]: batch[key].to(device) for key in followup_image_keys if \"seg\" not in key\n",
    "        }\n",
    "\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            outputs = model(baseline_images, followup_images)\n",
    "            loss = loss_fn(outputs, batch[\"label\"]) / accumulation_steps  # Scale loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        accuracy = np.mean(preds == batch[\"label\"].cpu().numpy())\n",
    "        total_acc += accuracy\n",
    "        \n",
    "        step_count += 1\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if wandb_logging:\n",
    "                wandb.log({\n",
    "                    'train_loss': total_loss / step_count,\n",
    "                    'train_accuracy': total_acc / step_count,\n",
    "                })\n",
    "            \n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            step_count = 0\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    return {\n",
    "        'train_loss': total_loss / max(1, step_count),\n",
    "        'train_accuracy': total_acc / max(1, step_count)\n",
    "    }\n",
    "        \n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader, loss_fn, device, scheduler=None, wandb_logging=False):\n",
    "    model.eval()\n",
    "    batches_cnt = 0\n",
    "    accuracy_acum = 0\n",
    "    accuracy_per_class = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "    samples_cnt_per_class = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "\n",
    "    for batch in tqdm(loader, leave=False):\n",
    "        # batch = batch[0]\n",
    "        batch[\"label\"] = batch[\"label\"].to(device)\n",
    "        baseline_images = {\n",
    "            key.split(\"_\")[-1]: batch[key].to(device) for key in baseline_image_keys if \"seg\" not in key\n",
    "        }\n",
    "        followup_images = {\n",
    "            key.split(\"_\")[-1]: batch[key].to(device) for key in followup_image_keys if \"seg\" not in key\n",
    "        }\n",
    "\n",
    "        outputs = model(baseline_images, followup_images)\n",
    "        loss = loss_fn(outputs, batch[\"label\"])\n",
    "\n",
    "        # ===================\n",
    "        # METRICS CALCULATION\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        accuracy = np.mean(preds == batch[\"label\"].cpu().numpy())\n",
    "        for i in range(NUM_CLASSES):\n",
    "            accuracy_per_class[i] += np.sum(preds[batch[\"label\"].cpu().numpy() == i] == i) if np.any(batch[\"label\"].cpu().numpy() == i) else 0\n",
    "            samples_cnt_per_class[i] += np.sum(batch[\"label\"].cpu().numpy() == i)\n",
    "        accuracy_acum += accuracy\n",
    "        batches_cnt += 1\n",
    "        # ===================\n",
    "    print(accuracy_per_class, samples_cnt_per_class)\n",
    "    valid_logs = {\n",
    "        'valid_loss': loss.item(),\n",
    "        'valid_accuracy': accuracy_acum / batches_cnt,\n",
    "        'valid_accuracy_0': accuracy_per_class[0] / samples_cnt_per_class[0],\n",
    "        'valid_accuracy_1': accuracy_per_class[1] / samples_cnt_per_class[1],\n",
    "        'valid_accuracy_2': accuracy_per_class[2] / samples_cnt_per_class[2],\n",
    "        'valid_accuracy_3': accuracy_per_class[3] / samples_cnt_per_class[3],\n",
    "    }\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step(valid_logs['valid_accuracy'])\n",
    "        \n",
    "    if wandb_logging:\n",
    "        wandb.log(valid_logs)\n",
    "    \n",
    "    return valid_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74a9ff",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04e50d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb26af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BaselineModel(nn.Module):\n",
    "#     def __init__(self, encoder: nn.Module, emb_dim: int, dropout: float):\n",
    "#         super(BaselineModel, self).__init__()\n",
    "#         self.encoder = encoder\n",
    "#         self.head = nn.Sequential(\n",
    "#             nn.Linear(emb_dim, 4 * emb_dim),\n",
    "#             nn.LayerNorm(4 * emb_dim),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(dropout),\n",
    "#             nn.Linear(4 * emb_dim, NUM_CLASSES),\n",
    "#             nn.Softmax(dim=-1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, baseline, followup):\n",
    "#         baseline_embed = self.encoder(baseline.permute(0, 3, 1, 2))\n",
    "#         followup_embed = self.encoder(followup.permute(0, 3, 1, 2))\n",
    "#         # growing_embed = self.encoder(followup.permute(0, 3, 1, 2) - baseline.permute(0, 3, 1, 2))\n",
    "\n",
    "#         # baseline_segm_mask = (baseline[:, 4] > 0)\n",
    "#         # followup_segm_mask = (followup[:, 4] > 0)\n",
    "\n",
    "#         # baseline[:, :4] = baseline[:, :4] * baseline_segm_mask.unsqueeze(1)\n",
    "#         # followup[:, :4] = followup[:, :4] * followup_segm_mask.unsqueeze(1)\n",
    "\n",
    "#         # baseline_embed = self.encoder(baseline)\n",
    "#         # followup_embed = self.encoder(followup)\n",
    "#         # joint_embed = self.encoder(followup - baseline)\n",
    "#         # joint_embed = torch.cat([baseline_embed, followup_embed], dim=1)\n",
    "#         joint_embed = followup_embed - baseline_embed\n",
    "#         outputs = self.head(joint_embed)\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10647385",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS_TOKEN_IDX = 0\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, dropout: float):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.dif = nn.Sequential(\n",
    "            nn.Linear(encoder.hidden_size, 2 * encoder.hidden_size),\n",
    "            nn.LayerNorm(2 * encoder.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(4 * encoder.hidden_size, encoder.hidden_size),\n",
    "            nn.LayerNorm(encoder.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(encoder.hidden_size, NUM_CLASSES),\n",
    "            nn.Softmax(dim=-1) # FOCAL LOSS ONLY\n",
    "        )\n",
    "\n",
    "    def forward(self, baseline, followup):\n",
    "        baseline_embed = self.encoder(baseline)[:, CLS_TOKEN_IDX]\n",
    "        followup_embed = self.encoder(followup)[:, CLS_TOKEN_IDX]\n",
    "        # growing_embed = self.encoder(followup.permute(0, 3, 1, 2) - baseline.permute(0, 3, 1, 2))\n",
    "\n",
    "        # baseline_segm_mask = (baseline[:, 4] > 0)\n",
    "        # followup_segm_mask = (followup[:, 4] > 0)\n",
    "\n",
    "        # baseline[:, :4] = baseline[:, :4] * baseline_segm_mask.unsqueeze(1)\n",
    "        # followup[:, :4] = followup[:, :4] * followup_segm_mask.unsqueeze(1)\n",
    "\n",
    "        # baseline_embed = self.encoder(baseline)\n",
    "        # followup_embed = self.encoder(followup)\n",
    "        # joint_embed = self.encoder(followup - baseline)\n",
    "        # joint_embed = torch.cat([baseline_embed, followup_embed], dim=1)\n",
    "        delta_embed = self.dif(followup_embed - baseline_embed)\n",
    "        # joint_embed = followup_embed - baseline_embed\n",
    "        outputs = self.clf(torch.cat([baseline_embed, followup_embed, delta_embed], dim=1))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "856b70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monai.networks.nets import DenseNet121\n",
    "\n",
    "NUM_CHANNELS = 10\n",
    "# EMB_DIM = 128\n",
    "DROPOUT = 0.0\n",
    "ENCODER_DROPOUT = 0.00\n",
    "\n",
    "def get_model() -> nn.Module:\n",
    "    modalities = [\"T1\", \"T1CE\", \"T2\", \"FLAIR\"]\n",
    "    tokenizers = {\n",
    "        modality: MRITokenizer(\n",
    "            patch_size=(16, 16, 16),\n",
    "            img_size=(128, 128, 128),\n",
    "            hidden_size=768,\n",
    "        )\n",
    "        for modality in modalities\n",
    "    }\n",
    "    encoder = ViTEncoder(\n",
    "        modalities=modalities,\n",
    "        tokenizers=tokenizers,\n",
    "        cls_token=True,\n",
    "        dropout_rate=ENCODER_DROPOUT\n",
    "    )\n",
    "\n",
    "    state_dict = torch.load(BMMAE_PATH / 'pretrained_models/bmmae.pth')\n",
    "    encoder.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    for name, param in encoder.named_parameters():\n",
    "        # if all(x not in name for x in [\"blocks.11\", \"cls_token\"]):\n",
    "        if all(x not in name for x in [\"blocks.11\"]):\n",
    "            print(f\"Freezing {name}\")\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            print(f\"Unfreezing {name}\")\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    model = BaselineModel(\n",
    "        encoder=encoder,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9a25e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd851eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 128, 128, 128]), torch.Size([2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"baseline_FLAIR\"].shape, batch[\"label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e249aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing cls_token\n",
      "Freezing tokenizers.T1.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.T1.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.T1.patch_embedding.patch_embeddings.bias\n",
      "Freezing tokenizers.T1CE.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.T1CE.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.T1CE.patch_embedding.patch_embeddings.bias\n",
      "Freezing tokenizers.T2.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.T2.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.T2.patch_embedding.patch_embeddings.bias\n",
      "Freezing tokenizers.FLAIR.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.FLAIR.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.FLAIR.patch_embedding.patch_embeddings.bias\n",
      "Freezing norm.weight\n",
      "Freezing norm.bias\n",
      "Freezing blocks.0.mlp.linear1.weight\n",
      "Freezing blocks.0.mlp.linear1.bias\n",
      "Freezing blocks.0.mlp.linear2.weight\n",
      "Freezing blocks.0.mlp.linear2.bias\n",
      "Freezing blocks.0.norm1.weight\n",
      "Freezing blocks.0.norm1.bias\n",
      "Freezing blocks.0.attn.out_proj.weight\n",
      "Freezing blocks.0.attn.out_proj.bias\n",
      "Freezing blocks.0.attn.qkv.weight\n",
      "Freezing blocks.0.attn.qkv.bias\n",
      "Freezing blocks.0.norm2.weight\n",
      "Freezing blocks.0.norm2.bias\n",
      "Freezing blocks.0.norm_cross_attn.weight\n",
      "Freezing blocks.0.norm_cross_attn.bias\n",
      "Freezing blocks.0.cross_attn.out_proj.weight\n",
      "Freezing blocks.0.cross_attn.out_proj.bias\n",
      "Freezing blocks.0.cross_attn.to_q.weight\n",
      "Freezing blocks.0.cross_attn.to_q.bias\n",
      "Freezing blocks.0.cross_attn.to_k.weight\n",
      "Freezing blocks.0.cross_attn.to_k.bias\n",
      "Freezing blocks.0.cross_attn.to_v.weight\n",
      "Freezing blocks.0.cross_attn.to_v.bias\n",
      "Freezing blocks.1.mlp.linear1.weight\n",
      "Freezing blocks.1.mlp.linear1.bias\n",
      "Freezing blocks.1.mlp.linear2.weight\n",
      "Freezing blocks.1.mlp.linear2.bias\n",
      "Freezing blocks.1.norm1.weight\n",
      "Freezing blocks.1.norm1.bias\n",
      "Freezing blocks.1.attn.out_proj.weight\n",
      "Freezing blocks.1.attn.out_proj.bias\n",
      "Freezing blocks.1.attn.qkv.weight\n",
      "Freezing blocks.1.attn.qkv.bias\n",
      "Freezing blocks.1.norm2.weight\n",
      "Freezing blocks.1.norm2.bias\n",
      "Freezing blocks.1.norm_cross_attn.weight\n",
      "Freezing blocks.1.norm_cross_attn.bias\n",
      "Freezing blocks.1.cross_attn.out_proj.weight\n",
      "Freezing blocks.1.cross_attn.out_proj.bias\n",
      "Freezing blocks.1.cross_attn.to_q.weight\n",
      "Freezing blocks.1.cross_attn.to_q.bias\n",
      "Freezing blocks.1.cross_attn.to_k.weight\n",
      "Freezing blocks.1.cross_attn.to_k.bias\n",
      "Freezing blocks.1.cross_attn.to_v.weight\n",
      "Freezing blocks.1.cross_attn.to_v.bias\n",
      "Freezing blocks.2.mlp.linear1.weight\n",
      "Freezing blocks.2.mlp.linear1.bias\n",
      "Freezing blocks.2.mlp.linear2.weight\n",
      "Freezing blocks.2.mlp.linear2.bias\n",
      "Freezing blocks.2.norm1.weight\n",
      "Freezing blocks.2.norm1.bias\n",
      "Freezing blocks.2.attn.out_proj.weight\n",
      "Freezing blocks.2.attn.out_proj.bias\n",
      "Freezing blocks.2.attn.qkv.weight\n",
      "Freezing blocks.2.attn.qkv.bias\n",
      "Freezing blocks.2.norm2.weight\n",
      "Freezing blocks.2.norm2.bias\n",
      "Freezing blocks.2.norm_cross_attn.weight\n",
      "Freezing blocks.2.norm_cross_attn.bias\n",
      "Freezing blocks.2.cross_attn.out_proj.weight\n",
      "Freezing blocks.2.cross_attn.out_proj.bias\n",
      "Freezing blocks.2.cross_attn.to_q.weight\n",
      "Freezing blocks.2.cross_attn.to_q.bias\n",
      "Freezing blocks.2.cross_attn.to_k.weight\n",
      "Freezing blocks.2.cross_attn.to_k.bias\n",
      "Freezing blocks.2.cross_attn.to_v.weight\n",
      "Freezing blocks.2.cross_attn.to_v.bias\n",
      "Freezing blocks.3.mlp.linear1.weight\n",
      "Freezing blocks.3.mlp.linear1.bias\n",
      "Freezing blocks.3.mlp.linear2.weight\n",
      "Freezing blocks.3.mlp.linear2.bias\n",
      "Freezing blocks.3.norm1.weight\n",
      "Freezing blocks.3.norm1.bias\n",
      "Freezing blocks.3.attn.out_proj.weight\n",
      "Freezing blocks.3.attn.out_proj.bias\n",
      "Freezing blocks.3.attn.qkv.weight\n",
      "Freezing blocks.3.attn.qkv.bias\n",
      "Freezing blocks.3.norm2.weight\n",
      "Freezing blocks.3.norm2.bias\n",
      "Freezing blocks.3.norm_cross_attn.weight\n",
      "Freezing blocks.3.norm_cross_attn.bias\n",
      "Freezing blocks.3.cross_attn.out_proj.weight\n",
      "Freezing blocks.3.cross_attn.out_proj.bias\n",
      "Freezing blocks.3.cross_attn.to_q.weight\n",
      "Freezing blocks.3.cross_attn.to_q.bias\n",
      "Freezing blocks.3.cross_attn.to_k.weight\n",
      "Freezing blocks.3.cross_attn.to_k.bias\n",
      "Freezing blocks.3.cross_attn.to_v.weight\n",
      "Freezing blocks.3.cross_attn.to_v.bias\n",
      "Freezing blocks.4.mlp.linear1.weight\n",
      "Freezing blocks.4.mlp.linear1.bias\n",
      "Freezing blocks.4.mlp.linear2.weight\n",
      "Freezing blocks.4.mlp.linear2.bias\n",
      "Freezing blocks.4.norm1.weight\n",
      "Freezing blocks.4.norm1.bias\n",
      "Freezing blocks.4.attn.out_proj.weight\n",
      "Freezing blocks.4.attn.out_proj.bias\n",
      "Freezing blocks.4.attn.qkv.weight\n",
      "Freezing blocks.4.attn.qkv.bias\n",
      "Freezing blocks.4.norm2.weight\n",
      "Freezing blocks.4.norm2.bias\n",
      "Freezing blocks.4.norm_cross_attn.weight\n",
      "Freezing blocks.4.norm_cross_attn.bias\n",
      "Freezing blocks.4.cross_attn.out_proj.weight\n",
      "Freezing blocks.4.cross_attn.out_proj.bias\n",
      "Freezing blocks.4.cross_attn.to_q.weight\n",
      "Freezing blocks.4.cross_attn.to_q.bias\n",
      "Freezing blocks.4.cross_attn.to_k.weight\n",
      "Freezing blocks.4.cross_attn.to_k.bias\n",
      "Freezing blocks.4.cross_attn.to_v.weight\n",
      "Freezing blocks.4.cross_attn.to_v.bias\n",
      "Freezing blocks.5.mlp.linear1.weight\n",
      "Freezing blocks.5.mlp.linear1.bias\n",
      "Freezing blocks.5.mlp.linear2.weight\n",
      "Freezing blocks.5.mlp.linear2.bias\n",
      "Freezing blocks.5.norm1.weight\n",
      "Freezing blocks.5.norm1.bias\n",
      "Freezing blocks.5.attn.out_proj.weight\n",
      "Freezing blocks.5.attn.out_proj.bias\n",
      "Freezing blocks.5.attn.qkv.weight\n",
      "Freezing blocks.5.attn.qkv.bias\n",
      "Freezing blocks.5.norm2.weight\n",
      "Freezing blocks.5.norm2.bias\n",
      "Freezing blocks.5.norm_cross_attn.weight\n",
      "Freezing blocks.5.norm_cross_attn.bias\n",
      "Freezing blocks.5.cross_attn.out_proj.weight\n",
      "Freezing blocks.5.cross_attn.out_proj.bias\n",
      "Freezing blocks.5.cross_attn.to_q.weight\n",
      "Freezing blocks.5.cross_attn.to_q.bias\n",
      "Freezing blocks.5.cross_attn.to_k.weight\n",
      "Freezing blocks.5.cross_attn.to_k.bias\n",
      "Freezing blocks.5.cross_attn.to_v.weight\n",
      "Freezing blocks.5.cross_attn.to_v.bias\n",
      "Freezing blocks.6.mlp.linear1.weight\n",
      "Freezing blocks.6.mlp.linear1.bias\n",
      "Freezing blocks.6.mlp.linear2.weight\n",
      "Freezing blocks.6.mlp.linear2.bias\n",
      "Freezing blocks.6.norm1.weight\n",
      "Freezing blocks.6.norm1.bias\n",
      "Freezing blocks.6.attn.out_proj.weight\n",
      "Freezing blocks.6.attn.out_proj.bias\n",
      "Freezing blocks.6.attn.qkv.weight\n",
      "Freezing blocks.6.attn.qkv.bias\n",
      "Freezing blocks.6.norm2.weight\n",
      "Freezing blocks.6.norm2.bias\n",
      "Freezing blocks.6.norm_cross_attn.weight\n",
      "Freezing blocks.6.norm_cross_attn.bias\n",
      "Freezing blocks.6.cross_attn.out_proj.weight\n",
      "Freezing blocks.6.cross_attn.out_proj.bias\n",
      "Freezing blocks.6.cross_attn.to_q.weight\n",
      "Freezing blocks.6.cross_attn.to_q.bias\n",
      "Freezing blocks.6.cross_attn.to_k.weight\n",
      "Freezing blocks.6.cross_attn.to_k.bias\n",
      "Freezing blocks.6.cross_attn.to_v.weight\n",
      "Freezing blocks.6.cross_attn.to_v.bias\n",
      "Freezing blocks.7.mlp.linear1.weight\n",
      "Freezing blocks.7.mlp.linear1.bias\n",
      "Freezing blocks.7.mlp.linear2.weight\n",
      "Freezing blocks.7.mlp.linear2.bias\n",
      "Freezing blocks.7.norm1.weight\n",
      "Freezing blocks.7.norm1.bias\n",
      "Freezing blocks.7.attn.out_proj.weight\n",
      "Freezing blocks.7.attn.out_proj.bias\n",
      "Freezing blocks.7.attn.qkv.weight\n",
      "Freezing blocks.7.attn.qkv.bias\n",
      "Freezing blocks.7.norm2.weight\n",
      "Freezing blocks.7.norm2.bias\n",
      "Freezing blocks.7.norm_cross_attn.weight\n",
      "Freezing blocks.7.norm_cross_attn.bias\n",
      "Freezing blocks.7.cross_attn.out_proj.weight\n",
      "Freezing blocks.7.cross_attn.out_proj.bias\n",
      "Freezing blocks.7.cross_attn.to_q.weight\n",
      "Freezing blocks.7.cross_attn.to_q.bias\n",
      "Freezing blocks.7.cross_attn.to_k.weight\n",
      "Freezing blocks.7.cross_attn.to_k.bias\n",
      "Freezing blocks.7.cross_attn.to_v.weight\n",
      "Freezing blocks.7.cross_attn.to_v.bias\n",
      "Freezing blocks.8.mlp.linear1.weight\n",
      "Freezing blocks.8.mlp.linear1.bias\n",
      "Freezing blocks.8.mlp.linear2.weight\n",
      "Freezing blocks.8.mlp.linear2.bias\n",
      "Freezing blocks.8.norm1.weight\n",
      "Freezing blocks.8.norm1.bias\n",
      "Freezing blocks.8.attn.out_proj.weight\n",
      "Freezing blocks.8.attn.out_proj.bias\n",
      "Freezing blocks.8.attn.qkv.weight\n",
      "Freezing blocks.8.attn.qkv.bias\n",
      "Freezing blocks.8.norm2.weight\n",
      "Freezing blocks.8.norm2.bias\n",
      "Freezing blocks.8.norm_cross_attn.weight\n",
      "Freezing blocks.8.norm_cross_attn.bias\n",
      "Freezing blocks.8.cross_attn.out_proj.weight\n",
      "Freezing blocks.8.cross_attn.out_proj.bias\n",
      "Freezing blocks.8.cross_attn.to_q.weight\n",
      "Freezing blocks.8.cross_attn.to_q.bias\n",
      "Freezing blocks.8.cross_attn.to_k.weight\n",
      "Freezing blocks.8.cross_attn.to_k.bias\n",
      "Freezing blocks.8.cross_attn.to_v.weight\n",
      "Freezing blocks.8.cross_attn.to_v.bias\n",
      "Freezing blocks.9.mlp.linear1.weight\n",
      "Freezing blocks.9.mlp.linear1.bias\n",
      "Freezing blocks.9.mlp.linear2.weight\n",
      "Freezing blocks.9.mlp.linear2.bias\n",
      "Freezing blocks.9.norm1.weight\n",
      "Freezing blocks.9.norm1.bias\n",
      "Freezing blocks.9.attn.out_proj.weight\n",
      "Freezing blocks.9.attn.out_proj.bias\n",
      "Freezing blocks.9.attn.qkv.weight\n",
      "Freezing blocks.9.attn.qkv.bias\n",
      "Freezing blocks.9.norm2.weight\n",
      "Freezing blocks.9.norm2.bias\n",
      "Freezing blocks.9.norm_cross_attn.weight\n",
      "Freezing blocks.9.norm_cross_attn.bias\n",
      "Freezing blocks.9.cross_attn.out_proj.weight\n",
      "Freezing blocks.9.cross_attn.out_proj.bias\n",
      "Freezing blocks.9.cross_attn.to_q.weight\n",
      "Freezing blocks.9.cross_attn.to_q.bias\n",
      "Freezing blocks.9.cross_attn.to_k.weight\n",
      "Freezing blocks.9.cross_attn.to_k.bias\n",
      "Freezing blocks.9.cross_attn.to_v.weight\n",
      "Freezing blocks.9.cross_attn.to_v.bias\n",
      "Freezing blocks.10.mlp.linear1.weight\n",
      "Freezing blocks.10.mlp.linear1.bias\n",
      "Freezing blocks.10.mlp.linear2.weight\n",
      "Freezing blocks.10.mlp.linear2.bias\n",
      "Freezing blocks.10.norm1.weight\n",
      "Freezing blocks.10.norm1.bias\n",
      "Freezing blocks.10.attn.out_proj.weight\n",
      "Freezing blocks.10.attn.out_proj.bias\n",
      "Freezing blocks.10.attn.qkv.weight\n",
      "Freezing blocks.10.attn.qkv.bias\n",
      "Freezing blocks.10.norm2.weight\n",
      "Freezing blocks.10.norm2.bias\n",
      "Freezing blocks.10.norm_cross_attn.weight\n",
      "Freezing blocks.10.norm_cross_attn.bias\n",
      "Freezing blocks.10.cross_attn.out_proj.weight\n",
      "Freezing blocks.10.cross_attn.out_proj.bias\n",
      "Freezing blocks.10.cross_attn.to_q.weight\n",
      "Freezing blocks.10.cross_attn.to_q.bias\n",
      "Freezing blocks.10.cross_attn.to_k.weight\n",
      "Freezing blocks.10.cross_attn.to_k.bias\n",
      "Freezing blocks.10.cross_attn.to_v.weight\n",
      "Freezing blocks.10.cross_attn.to_v.bias\n",
      "Unfreezing blocks.11.mlp.linear1.weight\n",
      "Unfreezing blocks.11.mlp.linear1.bias\n",
      "Unfreezing blocks.11.mlp.linear2.weight\n",
      "Unfreezing blocks.11.mlp.linear2.bias\n",
      "Unfreezing blocks.11.norm1.weight\n",
      "Unfreezing blocks.11.norm1.bias\n",
      "Unfreezing blocks.11.attn.out_proj.weight\n",
      "Unfreezing blocks.11.attn.out_proj.bias\n",
      "Unfreezing blocks.11.attn.qkv.weight\n",
      "Unfreezing blocks.11.attn.qkv.bias\n",
      "Unfreezing blocks.11.norm2.weight\n",
      "Unfreezing blocks.11.norm2.bias\n",
      "Unfreezing blocks.11.norm_cross_attn.weight\n",
      "Unfreezing blocks.11.norm_cross_attn.bias\n",
      "Unfreezing blocks.11.cross_attn.out_proj.weight\n",
      "Unfreezing blocks.11.cross_attn.out_proj.bias\n",
      "Unfreezing blocks.11.cross_attn.to_q.weight\n",
      "Unfreezing blocks.11.cross_attn.to_q.bias\n",
      "Unfreezing blocks.11.cross_attn.to_k.weight\n",
      "Unfreezing blocks.11.cross_attn.to_k.bias\n",
      "Unfreezing blocks.11.cross_attn.to_v.weight\n",
      "Unfreezing blocks.11.cross_attn.to_v.bias\n",
      "All gucci\n"
     ]
    }
   ],
   "source": [
    "baseline_model = get_model()\n",
    "test_model_correctness(baseline_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baf4b683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.64 M'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_params(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89223bd9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a732043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_pipeline(\n",
    "    epochs, model, train_loader, valid_loader, loss_fn, optimizer, device,\n",
    "    scheduler=None, wandb_logging=False,\n",
    "    checkpoint_freq: int = None, checkpoint_name: str = None\n",
    "):\n",
    "    seed_everything()\n",
    "    model = model.to(device)\n",
    "    train_logs, valid_logs = [], []\n",
    "\n",
    "    if wandb_logging:\n",
    "        wandb.init(\n",
    "            project=\"MRI Classification\",\n",
    "            name=\"FFA\",\n",
    "            config={\"desc\": \"Doing something\"}\n",
    "        )\n",
    "\n",
    "    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "        train_scheduler = None\n",
    "        valid_scheduler = scheduler\n",
    "    else:\n",
    "        train_scheduler = scheduler\n",
    "        valid_scheduler = None\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_log = train(\n",
    "            model=model,\n",
    "            loader=train_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            scheduler=train_scheduler,\n",
    "            wandb_logging=wandb_logging\n",
    "        )\n",
    "        train_logs.append(train_log)\n",
    "\n",
    "        valid_log = evaluate(\n",
    "            model=model,\n",
    "            loader=valid_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device,\n",
    "            scheduler=valid_scheduler,\n",
    "            wandb_logging=wandb_logging\n",
    "        )\n",
    "        valid_logs.append(valid_log)\n",
    "\n",
    "        if checkpoint_freq is not None:\n",
    "            checkpoint = {\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"train_scheduler_state\": None if train_scheduler is None else train_scheduler.state_dict(),\n",
    "                \"valid_scheduler_state\": None if valid_scheduler is None else valid_scheduler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, PATH_TO_MODELS / f\"{checkpoint_name}_{epoch + 1}.pth\")\n",
    "            # REMOVE PREVIOUS CHECKPOINT\n",
    "            if epoch + 1 != checkpoint_freq:\n",
    "                os.remove(PATH_TO_MODELS / f\"{checkpoint_name}_{epoch + 1 - checkpoint_freq}.pth\")\n",
    "\n",
    "        if wandb_logging:\n",
    "            wandb.log({'learning_rate': optimizer.param_groups[0]['lr']})\n",
    "    \n",
    "    if wandb_logging:\n",
    "        wandb.finish()\n",
    "    \n",
    "    return train_logs, valid_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16a9736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing cls_token\n",
      "Freezing tokenizers.T1.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.T1.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.T1.patch_embedding.patch_embeddings.bias\n",
      "Freezing tokenizers.T1CE.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.T1CE.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.T1CE.patch_embedding.patch_embeddings.bias\n",
      "Freezing tokenizers.T2.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.T2.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.T2.patch_embedding.patch_embeddings.bias\n",
      "Freezing tokenizers.FLAIR.patch_embedding.position_embeddings\n",
      "Freezing tokenizers.FLAIR.patch_embedding.patch_embeddings.weight\n",
      "Freezing tokenizers.FLAIR.patch_embedding.patch_embeddings.bias\n",
      "Freezing norm.weight\n",
      "Freezing norm.bias\n",
      "Freezing blocks.0.mlp.linear1.weight\n",
      "Freezing blocks.0.mlp.linear1.bias\n",
      "Freezing blocks.0.mlp.linear2.weight\n",
      "Freezing blocks.0.mlp.linear2.bias\n",
      "Freezing blocks.0.norm1.weight\n",
      "Freezing blocks.0.norm1.bias\n",
      "Freezing blocks.0.attn.out_proj.weight\n",
      "Freezing blocks.0.attn.out_proj.bias\n",
      "Freezing blocks.0.attn.qkv.weight\n",
      "Freezing blocks.0.attn.qkv.bias\n",
      "Freezing blocks.0.norm2.weight\n",
      "Freezing blocks.0.norm2.bias\n",
      "Freezing blocks.0.norm_cross_attn.weight\n",
      "Freezing blocks.0.norm_cross_attn.bias\n",
      "Freezing blocks.0.cross_attn.out_proj.weight\n",
      "Freezing blocks.0.cross_attn.out_proj.bias\n",
      "Freezing blocks.0.cross_attn.to_q.weight\n",
      "Freezing blocks.0.cross_attn.to_q.bias\n",
      "Freezing blocks.0.cross_attn.to_k.weight\n",
      "Freezing blocks.0.cross_attn.to_k.bias\n",
      "Freezing blocks.0.cross_attn.to_v.weight\n",
      "Freezing blocks.0.cross_attn.to_v.bias\n",
      "Freezing blocks.1.mlp.linear1.weight\n",
      "Freezing blocks.1.mlp.linear1.bias\n",
      "Freezing blocks.1.mlp.linear2.weight\n",
      "Freezing blocks.1.mlp.linear2.bias\n",
      "Freezing blocks.1.norm1.weight\n",
      "Freezing blocks.1.norm1.bias\n",
      "Freezing blocks.1.attn.out_proj.weight\n",
      "Freezing blocks.1.attn.out_proj.bias\n",
      "Freezing blocks.1.attn.qkv.weight\n",
      "Freezing blocks.1.attn.qkv.bias\n",
      "Freezing blocks.1.norm2.weight\n",
      "Freezing blocks.1.norm2.bias\n",
      "Freezing blocks.1.norm_cross_attn.weight\n",
      "Freezing blocks.1.norm_cross_attn.bias\n",
      "Freezing blocks.1.cross_attn.out_proj.weight\n",
      "Freezing blocks.1.cross_attn.out_proj.bias\n",
      "Freezing blocks.1.cross_attn.to_q.weight\n",
      "Freezing blocks.1.cross_attn.to_q.bias\n",
      "Freezing blocks.1.cross_attn.to_k.weight\n",
      "Freezing blocks.1.cross_attn.to_k.bias\n",
      "Freezing blocks.1.cross_attn.to_v.weight\n",
      "Freezing blocks.1.cross_attn.to_v.bias\n",
      "Freezing blocks.2.mlp.linear1.weight\n",
      "Freezing blocks.2.mlp.linear1.bias\n",
      "Freezing blocks.2.mlp.linear2.weight\n",
      "Freezing blocks.2.mlp.linear2.bias\n",
      "Freezing blocks.2.norm1.weight\n",
      "Freezing blocks.2.norm1.bias\n",
      "Freezing blocks.2.attn.out_proj.weight\n",
      "Freezing blocks.2.attn.out_proj.bias\n",
      "Freezing blocks.2.attn.qkv.weight\n",
      "Freezing blocks.2.attn.qkv.bias\n",
      "Freezing blocks.2.norm2.weight\n",
      "Freezing blocks.2.norm2.bias\n",
      "Freezing blocks.2.norm_cross_attn.weight\n",
      "Freezing blocks.2.norm_cross_attn.bias\n",
      "Freezing blocks.2.cross_attn.out_proj.weight\n",
      "Freezing blocks.2.cross_attn.out_proj.bias\n",
      "Freezing blocks.2.cross_attn.to_q.weight\n",
      "Freezing blocks.2.cross_attn.to_q.bias\n",
      "Freezing blocks.2.cross_attn.to_k.weight\n",
      "Freezing blocks.2.cross_attn.to_k.bias\n",
      "Freezing blocks.2.cross_attn.to_v.weight\n",
      "Freezing blocks.2.cross_attn.to_v.bias\n",
      "Freezing blocks.3.mlp.linear1.weight\n",
      "Freezing blocks.3.mlp.linear1.bias\n",
      "Freezing blocks.3.mlp.linear2.weight\n",
      "Freezing blocks.3.mlp.linear2.bias\n",
      "Freezing blocks.3.norm1.weight\n",
      "Freezing blocks.3.norm1.bias\n",
      "Freezing blocks.3.attn.out_proj.weight\n",
      "Freezing blocks.3.attn.out_proj.bias\n",
      "Freezing blocks.3.attn.qkv.weight\n",
      "Freezing blocks.3.attn.qkv.bias\n",
      "Freezing blocks.3.norm2.weight\n",
      "Freezing blocks.3.norm2.bias\n",
      "Freezing blocks.3.norm_cross_attn.weight\n",
      "Freezing blocks.3.norm_cross_attn.bias\n",
      "Freezing blocks.3.cross_attn.out_proj.weight\n",
      "Freezing blocks.3.cross_attn.out_proj.bias\n",
      "Freezing blocks.3.cross_attn.to_q.weight\n",
      "Freezing blocks.3.cross_attn.to_q.bias\n",
      "Freezing blocks.3.cross_attn.to_k.weight\n",
      "Freezing blocks.3.cross_attn.to_k.bias\n",
      "Freezing blocks.3.cross_attn.to_v.weight\n",
      "Freezing blocks.3.cross_attn.to_v.bias\n",
      "Freezing blocks.4.mlp.linear1.weight\n",
      "Freezing blocks.4.mlp.linear1.bias\n",
      "Freezing blocks.4.mlp.linear2.weight\n",
      "Freezing blocks.4.mlp.linear2.bias\n",
      "Freezing blocks.4.norm1.weight\n",
      "Freezing blocks.4.norm1.bias\n",
      "Freezing blocks.4.attn.out_proj.weight\n",
      "Freezing blocks.4.attn.out_proj.bias\n",
      "Freezing blocks.4.attn.qkv.weight\n",
      "Freezing blocks.4.attn.qkv.bias\n",
      "Freezing blocks.4.norm2.weight\n",
      "Freezing blocks.4.norm2.bias\n",
      "Freezing blocks.4.norm_cross_attn.weight\n",
      "Freezing blocks.4.norm_cross_attn.bias\n",
      "Freezing blocks.4.cross_attn.out_proj.weight\n",
      "Freezing blocks.4.cross_attn.out_proj.bias\n",
      "Freezing blocks.4.cross_attn.to_q.weight\n",
      "Freezing blocks.4.cross_attn.to_q.bias\n",
      "Freezing blocks.4.cross_attn.to_k.weight\n",
      "Freezing blocks.4.cross_attn.to_k.bias\n",
      "Freezing blocks.4.cross_attn.to_v.weight\n",
      "Freezing blocks.4.cross_attn.to_v.bias\n",
      "Freezing blocks.5.mlp.linear1.weight\n",
      "Freezing blocks.5.mlp.linear1.bias\n",
      "Freezing blocks.5.mlp.linear2.weight\n",
      "Freezing blocks.5.mlp.linear2.bias\n",
      "Freezing blocks.5.norm1.weight\n",
      "Freezing blocks.5.norm1.bias\n",
      "Freezing blocks.5.attn.out_proj.weight\n",
      "Freezing blocks.5.attn.out_proj.bias\n",
      "Freezing blocks.5.attn.qkv.weight\n",
      "Freezing blocks.5.attn.qkv.bias\n",
      "Freezing blocks.5.norm2.weight\n",
      "Freezing blocks.5.norm2.bias\n",
      "Freezing blocks.5.norm_cross_attn.weight\n",
      "Freezing blocks.5.norm_cross_attn.bias\n",
      "Freezing blocks.5.cross_attn.out_proj.weight\n",
      "Freezing blocks.5.cross_attn.out_proj.bias\n",
      "Freezing blocks.5.cross_attn.to_q.weight\n",
      "Freezing blocks.5.cross_attn.to_q.bias\n",
      "Freezing blocks.5.cross_attn.to_k.weight\n",
      "Freezing blocks.5.cross_attn.to_k.bias\n",
      "Freezing blocks.5.cross_attn.to_v.weight\n",
      "Freezing blocks.5.cross_attn.to_v.bias\n",
      "Freezing blocks.6.mlp.linear1.weight\n",
      "Freezing blocks.6.mlp.linear1.bias\n",
      "Freezing blocks.6.mlp.linear2.weight\n",
      "Freezing blocks.6.mlp.linear2.bias\n",
      "Freezing blocks.6.norm1.weight\n",
      "Freezing blocks.6.norm1.bias\n",
      "Freezing blocks.6.attn.out_proj.weight\n",
      "Freezing blocks.6.attn.out_proj.bias\n",
      "Freezing blocks.6.attn.qkv.weight\n",
      "Freezing blocks.6.attn.qkv.bias\n",
      "Freezing blocks.6.norm2.weight\n",
      "Freezing blocks.6.norm2.bias\n",
      "Freezing blocks.6.norm_cross_attn.weight\n",
      "Freezing blocks.6.norm_cross_attn.bias\n",
      "Freezing blocks.6.cross_attn.out_proj.weight\n",
      "Freezing blocks.6.cross_attn.out_proj.bias\n",
      "Freezing blocks.6.cross_attn.to_q.weight\n",
      "Freezing blocks.6.cross_attn.to_q.bias\n",
      "Freezing blocks.6.cross_attn.to_k.weight\n",
      "Freezing blocks.6.cross_attn.to_k.bias\n",
      "Freezing blocks.6.cross_attn.to_v.weight\n",
      "Freezing blocks.6.cross_attn.to_v.bias\n",
      "Freezing blocks.7.mlp.linear1.weight\n",
      "Freezing blocks.7.mlp.linear1.bias\n",
      "Freezing blocks.7.mlp.linear2.weight\n",
      "Freezing blocks.7.mlp.linear2.bias\n",
      "Freezing blocks.7.norm1.weight\n",
      "Freezing blocks.7.norm1.bias\n",
      "Freezing blocks.7.attn.out_proj.weight\n",
      "Freezing blocks.7.attn.out_proj.bias\n",
      "Freezing blocks.7.attn.qkv.weight\n",
      "Freezing blocks.7.attn.qkv.bias\n",
      "Freezing blocks.7.norm2.weight\n",
      "Freezing blocks.7.norm2.bias\n",
      "Freezing blocks.7.norm_cross_attn.weight\n",
      "Freezing blocks.7.norm_cross_attn.bias\n",
      "Freezing blocks.7.cross_attn.out_proj.weight\n",
      "Freezing blocks.7.cross_attn.out_proj.bias\n",
      "Freezing blocks.7.cross_attn.to_q.weight\n",
      "Freezing blocks.7.cross_attn.to_q.bias\n",
      "Freezing blocks.7.cross_attn.to_k.weight\n",
      "Freezing blocks.7.cross_attn.to_k.bias\n",
      "Freezing blocks.7.cross_attn.to_v.weight\n",
      "Freezing blocks.7.cross_attn.to_v.bias\n",
      "Freezing blocks.8.mlp.linear1.weight\n",
      "Freezing blocks.8.mlp.linear1.bias\n",
      "Freezing blocks.8.mlp.linear2.weight\n",
      "Freezing blocks.8.mlp.linear2.bias\n",
      "Freezing blocks.8.norm1.weight\n",
      "Freezing blocks.8.norm1.bias\n",
      "Freezing blocks.8.attn.out_proj.weight\n",
      "Freezing blocks.8.attn.out_proj.bias\n",
      "Freezing blocks.8.attn.qkv.weight\n",
      "Freezing blocks.8.attn.qkv.bias\n",
      "Freezing blocks.8.norm2.weight\n",
      "Freezing blocks.8.norm2.bias\n",
      "Freezing blocks.8.norm_cross_attn.weight\n",
      "Freezing blocks.8.norm_cross_attn.bias\n",
      "Freezing blocks.8.cross_attn.out_proj.weight\n",
      "Freezing blocks.8.cross_attn.out_proj.bias\n",
      "Freezing blocks.8.cross_attn.to_q.weight\n",
      "Freezing blocks.8.cross_attn.to_q.bias\n",
      "Freezing blocks.8.cross_attn.to_k.weight\n",
      "Freezing blocks.8.cross_attn.to_k.bias\n",
      "Freezing blocks.8.cross_attn.to_v.weight\n",
      "Freezing blocks.8.cross_attn.to_v.bias\n",
      "Freezing blocks.9.mlp.linear1.weight\n",
      "Freezing blocks.9.mlp.linear1.bias\n",
      "Freezing blocks.9.mlp.linear2.weight\n",
      "Freezing blocks.9.mlp.linear2.bias\n",
      "Freezing blocks.9.norm1.weight\n",
      "Freezing blocks.9.norm1.bias\n",
      "Freezing blocks.9.attn.out_proj.weight\n",
      "Freezing blocks.9.attn.out_proj.bias\n",
      "Freezing blocks.9.attn.qkv.weight\n",
      "Freezing blocks.9.attn.qkv.bias\n",
      "Freezing blocks.9.norm2.weight\n",
      "Freezing blocks.9.norm2.bias\n",
      "Freezing blocks.9.norm_cross_attn.weight\n",
      "Freezing blocks.9.norm_cross_attn.bias\n",
      "Freezing blocks.9.cross_attn.out_proj.weight\n",
      "Freezing blocks.9.cross_attn.out_proj.bias\n",
      "Freezing blocks.9.cross_attn.to_q.weight\n",
      "Freezing blocks.9.cross_attn.to_q.bias\n",
      "Freezing blocks.9.cross_attn.to_k.weight\n",
      "Freezing blocks.9.cross_attn.to_k.bias\n",
      "Freezing blocks.9.cross_attn.to_v.weight\n",
      "Freezing blocks.9.cross_attn.to_v.bias\n",
      "Freezing blocks.10.mlp.linear1.weight\n",
      "Freezing blocks.10.mlp.linear1.bias\n",
      "Freezing blocks.10.mlp.linear2.weight\n",
      "Freezing blocks.10.mlp.linear2.bias\n",
      "Freezing blocks.10.norm1.weight\n",
      "Freezing blocks.10.norm1.bias\n",
      "Freezing blocks.10.attn.out_proj.weight\n",
      "Freezing blocks.10.attn.out_proj.bias\n",
      "Freezing blocks.10.attn.qkv.weight\n",
      "Freezing blocks.10.attn.qkv.bias\n",
      "Freezing blocks.10.norm2.weight\n",
      "Freezing blocks.10.norm2.bias\n",
      "Freezing blocks.10.norm_cross_attn.weight\n",
      "Freezing blocks.10.norm_cross_attn.bias\n",
      "Freezing blocks.10.cross_attn.out_proj.weight\n",
      "Freezing blocks.10.cross_attn.out_proj.bias\n",
      "Freezing blocks.10.cross_attn.to_q.weight\n",
      "Freezing blocks.10.cross_attn.to_q.bias\n",
      "Freezing blocks.10.cross_attn.to_k.weight\n",
      "Freezing blocks.10.cross_attn.to_k.bias\n",
      "Freezing blocks.10.cross_attn.to_v.weight\n",
      "Freezing blocks.10.cross_attn.to_v.bias\n",
      "Unfreezing blocks.11.mlp.linear1.weight\n",
      "Unfreezing blocks.11.mlp.linear1.bias\n",
      "Unfreezing blocks.11.mlp.linear2.weight\n",
      "Unfreezing blocks.11.mlp.linear2.bias\n",
      "Unfreezing blocks.11.norm1.weight\n",
      "Unfreezing blocks.11.norm1.bias\n",
      "Unfreezing blocks.11.attn.out_proj.weight\n",
      "Unfreezing blocks.11.attn.out_proj.bias\n",
      "Unfreezing blocks.11.attn.qkv.weight\n",
      "Unfreezing blocks.11.attn.qkv.bias\n",
      "Unfreezing blocks.11.norm2.weight\n",
      "Unfreezing blocks.11.norm2.bias\n",
      "Unfreezing blocks.11.norm_cross_attn.weight\n",
      "Unfreezing blocks.11.norm_cross_attn.bias\n",
      "Unfreezing blocks.11.cross_attn.out_proj.weight\n",
      "Unfreezing blocks.11.cross_attn.out_proj.bias\n",
      "Unfreezing blocks.11.cross_attn.to_q.weight\n",
      "Unfreezing blocks.11.cross_attn.to_q.bias\n",
      "Unfreezing blocks.11.cross_attn.to_k.weight\n",
      "Unfreezing blocks.11.cross_attn.to_k.bias\n",
      "Unfreezing blocks.11.cross_attn.to_v.weight\n",
      "Unfreezing blocks.11.cross_attn.to_v.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10.64 M'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from focal_loss.focal_loss import FocalLoss\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MOMENTUM = 0.90\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "model = get_model()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = torch.optim.AdamW([\n",
    "#     {'params': model.encoder.parameters(), 'lr': LEARNING_RATE / 3},\n",
    "#     {'params': model.dif.parameters(), 'lr': LEARNING_RATE},\n",
    "#     {'params': model.clf.parameters(), 'lr': LEARNING_RATE}\n",
    "# ], weight_decay=WEIGHT_DECAY)\n",
    "# loss_fn = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS.to(device))\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=NUM_EPOCHS, eta_min=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer,\n",
    "#     max_lr=LEARNING_RATE,\n",
    "#     total_steps=NUM_EPOCHS,\n",
    "#     pct_start=0.25\n",
    "# )\n",
    "NUM_WARMUP_EPOCHS = int(0.08 * NUM_EPOCHS)\n",
    "# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, [\n",
    "#     torch.optim.lr_scheduler.LinearLR(optimizer, 1e-2, 1.0, total_iters=NUM_WARMUP_EPOCHS),  # Warmup\n",
    "#     torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS - NUM_WARMUP_EPOCHS, eta_min=1e-6)  # Main\n",
    "# ], [NUM_WARMUP_EPOCHS])\n",
    "loss_fn = FocalLoss(gamma=2.0)\n",
    "# weights = weights ** 0.5\n",
    "# loss_fn = FocalLoss(weights=weights.to(device), gamma=2.0)\n",
    "scheduler = None\n",
    "calculate_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "046d47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10a3a66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniil.tikhonov/mri/wandb/run-20250714_180751-cce1zhfy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dteakhperky-higher-school-of-economics/MRI%20Classification/runs/cce1zhfy' target=\"_blank\">FFA</a></strong> to <a href='https://wandb.ai/dteakhperky-higher-school-of-economics/MRI%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dteakhperky-higher-school-of-economics/MRI%20Classification' target=\"_blank\">https://wandb.ai/dteakhperky-higher-school-of-economics/MRI%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dteakhperky-higher-school-of-economics/MRI%20Classification/runs/cce1zhfy' target=\"_blank\">https://wandb.ai/dteakhperky-higher-school-of-economics/MRI%20Classification/runs/cce1zhfy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [03:44<6:09:48, 224.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  9. 21.] [ 0. 14. 16. 54.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [07:25<6:03:11, 222.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  3. 12.] [ 0. 14. 16. 54.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [11:05<5:58:16, 221.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1. 13.  6.] [ 0. 14. 16. 54.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [14:47<5:54:18, 221.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  6. 29.] [ 0. 14. 16. 54.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [18:23<5:47:29, 219.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0. 11.  8.] [ 0. 14. 16. 54.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [21:59<5:42:26, 218.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0. 11. 30.] [ 0. 14. 16. 54.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [25:36<5:37:37, 217.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0. 11. 19.] [ 0. 14. 16. 54.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [27:59<6:11:56, 239.96s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_logs, val_logs = \u001b[43mrun_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwandb_logging\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mrun_training_pipeline\u001b[39m\u001b[34m(epochs, model, train_loader, valid_loader, loss_fn, optimizer, device, scheduler, wandb_logging, checkpoint_freq, checkpoint_name)\u001b[39m\n\u001b[32m     22\u001b[39m     valid_scheduler = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     train_log = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwandb_logging\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwandb_logging\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     train_logs.append(train_log)\n\u001b[32m     36\u001b[39m     valid_log = evaluate(\n\u001b[32m     37\u001b[39m         model=model,\n\u001b[32m     38\u001b[39m         loader=valid_loader,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m         wandb_logging=wandb_logging\n\u001b[32m     43\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, loader, loss_fn, optimizer, device, scheduler, wandb_logging, accumulation_steps)\u001b[39m\n\u001b[32m     15\u001b[39m step_count = \u001b[32m0\u001b[39m\n\u001b[32m     17\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# batch = batch[0]\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbaseline_images\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbaseline_image_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/multiprocessing/connection.py:948\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    945\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m    950\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mri/lib/python3.11/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28mself\u001b[39m._selector.poll(timeout)\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_logs, val_logs = run_training_pipeline(\n",
    "    epochs=NUM_EPOCHS,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    wandb_logging=True,\n",
    "    checkpoint_freq=None,\n",
    "    checkpoint_name=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937468d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
